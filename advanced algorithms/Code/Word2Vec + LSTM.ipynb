{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29731,"status":"ok","timestamp":1729401262098,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"},"user_tz":-180},"id":"7E8zC-uPLco2","outputId":"78f2dd7a-2cc5-4ba9-e6da-f0f7dc5a4c3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1729401262443,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"},"user_tz":-180},"id":"DzYMK1tQM7Rt","outputId":"ad49b615-4bb6-459c-b4c9-899a30fa1a7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Malicious Macro Detection\n"," AdaBoostClassifier.joblib\n"," classifiers_recall_scores.joblib\n"," CNNClassifier.joblib\n"," DecisionTreeClassifier.joblib\n"," EDA.ipynb\n"," features_k_1000.joblib\n"," features_k_100.joblib\n"," features_k_10.joblib\n"," features_k_1200.joblib\n"," features_k_1500.joblib\n"," features_k_2000.joblib\n"," features_k_2500.joblib\n"," features_k_3000.joblib\n"," features_k_500.joblib\n"," features_k_50.joblib\n"," gnbClassifier.joblib\n"," GradientBoostingClassifier.joblib\n"," knnClassifier.joblib\n"," LSTMClassifier.joblib\n","'Macro Malware Detection using Machine Learning Techniques A New Approach '\n"," mlpClasifier.joblib\n"," \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n"," randomForestClassifier.joblib\n"," recall_scores.joblib\n"," RobertaClassifier.joblib\n"," svmClassifier.joblib\n"," test_dataset.csv\n"," test_loader.joblib\n"," test_loader.pkl\n"," tfidf_1000.joblib\n"," tfidf_100.joblib\n"," tfidf_10.joblib\n"," tfidf_1200.joblib\n"," tfidf_1500.joblib\n"," tfidf_2000.joblib\n"," tfidf_2500.joblib\n"," tfidf_3000.joblib\n"," tfidf_500.joblib\n"," tfidf_50.joblib\n"," train_dataset.csv\n"," trainer.joblib\n"," train_loader.joblib\n"," train_loader.pkl\n"," utils.py\n"," validation_dataset.csv\n"," val_loader.joblib\n"," val_loader.pkl\n"," vba_pipeline.py\n"," word2vec_model.joblib\n"," word2vec_model.pkl\n"," x_test_1000.joblib\n"," x_test_100.joblib\n"," x_test_10.joblib\n"," x_test_1200.joblib\n"," x_test_1500.joblib\n"," x_test_2000.joblib\n"," x_test_2500.joblib\n"," x_test_3000.joblib\n"," x_test_500.joblib\n"," x_test_50.joblib\n"," x_train_1000.joblib\n"," x_train_100.joblib\n"," x_train_10.joblib\n"," x_train_1200.joblib\n"," x_train_1500.joblib\n"," x_train_2000.joblib\n"," x_train_2500.joblib\n"," x_train_3000.joblib\n"," x_train_500.joblib\n"," x_train_50.joblib\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/Malicious Macro Detection\n","%ls"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":13546,"status":"ok","timestamp":1729401275981,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"},"user_tz":-180},"id":"hfer3YjOLbw4"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from gensim.models import Word2Vec\n","import numpy as np\n","import pandas as pd\n","from joblib import dump, load\n","from collections import Counter\n","from utils import save_loader\n","\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, precision_score, recall_score, f1_score"]},{"cell_type":"code","source":["def calculate_vocabulary_size(datasets):\n","    vocab_counter = Counter()\n","    for dataset in datasets:\n","        for code in dataset['vba_code']:\n","            tokens = code.split()  # Assuming whitespace tokenization\n","            vocab_counter.update(tokens)\n","    return len(vocab_counter), vocab_counter"],"metadata":{"id":"xr_sB-cGhMRS","executionInfo":{"status":"ok","timestamp":1729401275983,"user_tz":-180,"elapsed":22,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6My5TGvzi9wi","executionInfo":{"status":"ok","timestamp":1729401275983,"user_tz":-180,"elapsed":21,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}}},"outputs":[],"source":["class datasetForLstm(Dataset):\n","    def __init__(self, dataset, vocab_counter, max_seq_length=100):\n","        self.text = dataset['vba_code']\n","        self.label = dataset['label']\n","        self.vocab_counter = vocab_counter\n","        self.max_seq_length = max_seq_length\n","        self.word2idx = {word: idx for idx, (word, _) in enumerate(vocab_counter.items(), 1)}\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, idx):\n","        tokens = self.text[idx].split()  # Tokenize the VBA code\n","        indices = [self.word2idx.get(token, 0) for token in tokens]\n","        if len(indices) < self.max_seq_length:\n","            indices += [0] * (self.max_seq_length - len(indices))\n","        else:\n","            indices = indices[:self.max_seq_length]\n","        return torch.tensor(indices, dtype=torch.long), torch.tensor(self.label[idx], dtype=torch.long)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"U_LQnh6KdVoP","executionInfo":{"status":"ok","timestamp":1729401275984,"user_tz":-180,"elapsed":19,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}}},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, output_size, num_layers, dropout):\n","        super(LSTMModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(vocab_size, self.hidden_size)\n","        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, num_layers, dropout=dropout, batch_first=True)\n","        self.fc = nn.Linear(self.hidden_size, output_size)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        h_0 = torch.zeros(num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c_0 = torch.zeros(num_layers, x.size(0), self.hidden_size).to(x.device)\n","\n","        out, _ = self.lstm(x, (h_0, c_0))\n","        out = self.fc(out[:, -1, :])\n","        out = self.softmax(out)\n","        return out\n","\n","class LstmTrainer:\n","\n","  def __init__(self, model, train_loader, validation_loader, criterion, optimizer, num_epochs, device):\n","    self.model = model\n","    self.train_loader = train_loader\n","    self.validation_loader = validation_loader\n","    self.criterion = criterion\n","    self.optimizer = optimizer\n","    self.device = device\n","    self.num_epochs = num_epochs\n","\n","  def train_one_epoch(self):\n","    self.model.train()\n","    total_loss = 0\n","    for x_batch, y_batch in self.train_loader:\n","        x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n","        optimizer.zero_grad()\n","        outputs = self.model(x_batch)\n","        loss = self.criterion(outputs, y_batch)\n","        loss.backward()\n","        self.optimizer.step()\n","        total_loss += loss.item()\n","\n","    return total_loss/len(train_loader)\n","\n","  def evaluate(self, data_loader):\n","      self.model.eval()\n","      all_preds = []\n","      all_labels = []\n","\n","      with torch.no_grad():\n","          for x_batch, y_batch in data_loader:\n","              x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n","              outputs = self.model(x_batch)\n","              _, preds = torch.max(outputs, dim=1)\n","              all_preds.extend(preds.cpu().numpy())\n","              all_labels.extend(y_batch.cpu().numpy())\n","\n","      accuracy = accuracy_score(all_labels, all_preds)\n","      precision = precision_score(all_labels, all_preds)\n","      recall = recall_score(all_labels, all_preds)\n","      f1 = f1_score(all_labels, all_preds)\n","      conf_matrix = confusion_matrix(all_labels, all_preds)\n","\n","      return accuracy, precision, recall, f1, conf_matrix\n","\n","  def train(self):\n","    all_losses = []\n","    for epoch in range(self.num_epochs):\n","      train_loss = self.train_one_epoch()\n","      validation_accuracy, validation_precision, validation_recall, validation_f1, validation_conf_matrix = self.evaluate(self.validation_loader)\n","      print(f'Epoch {epoch+1}/{self.num_epochs}, Train Loss: {train_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f},  Precision: {validation_precision}, Recall: {validation_recall}, F1-score: {validation_f1}')\n","      all_losses.append(train_loss)\n","    return all_losses\n","\n","  def test(self, test_loader):\n","      test_accuracy, precision, recall, f1_score, conf_matrix = self.evaluate(test_loader)\n","      print(f'Test Accuracy: {test_accuracy:.2f}%, Precision: {precision}, Recall: {recall}, F1-score: {f1_score}')\n","      return test_accuracy, precision, recall, f1_score, conf_matrix\n"]},{"cell_type":"code","source":["train_set = pd.read_csv('train_dataset.csv', encoding='utf-16le')[['vba_code', 'label']]\n","val_set = pd.read_csv('validation_dataset.csv', encoding='utf-16le')[['vba_code', 'label']]\n","test_set = pd.read_csv('test_dataset.csv', encoding='utf-16le')[['vba_code', 'label']]\n","\n","mapper = {'white': 1, 'mal': 0}\n","train_set['label'] = train_set['label'].map(mapper)\n","val_set['label'] = val_set['label'].map(mapper)\n","test_set['label'] = test_set['label'].map(mapper)\n","\n","vocab_size, vocab_counter = calculate_vocabulary_size([train_set, val_set, test_set])\n","\n","train_set = datasetForLstm(train_set, vocab_counter)\n","val_set = datasetForLstm(val_set, vocab_counter)\n","test_set = datasetForLstm(test_set, vocab_counter)\n","\n","train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n","validation_loader = DataLoader(val_set, batch_size=32)\n","test_loader = DataLoader(test_set, batch_size=32)"],"metadata":{"id":"63idc-p-zzod","executionInfo":{"status":"ok","timestamp":1729401284121,"user_tz":-180,"elapsed":8156,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["hidden_size = 128\n","output_size = 2\n","num_layers = 2\n","dropout = 0.5\n","num_epochs = 10\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = LSTMModel(vocab_size + 1, hidden_size, output_size, num_layers, dropout).to(device)  # Add 1 for padding index\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train and evaluate the model\n","model_trainer  = LstmTrainer(model, train_loader, validation_loader, criterion, optimizer, num_epochs, device)\n","all_losses = model_trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9X69mWo2--J","executionInfo":{"status":"ok","timestamp":1729401499723,"user_tz":-180,"elapsed":215610,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}},"outputId":"1b0c5f70-deab-43eb-fffd-81923eb96993"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Train Loss: 0.4502, Validation Accuracy: 0.8950,  Precision: 0.8319873317498021, Recall: 0.9896402335656432, F1-score: 0.9039917412250517\n","Epoch 2/10, Train Loss: 0.3931, Validation Accuracy: 0.9136,  Precision: 0.9522142121524202, Recall: 0.8707854586551139, F1-score: 0.9096812278630461\n","Epoch 3/10, Train Loss: 0.4071, Validation Accuracy: 0.9161,  Precision: 0.9322763750244666, Recall: 0.8971557732152948, F1-score: 0.9143789594931848\n","Epoch 4/10, Train Loss: 0.3898, Validation Accuracy: 0.9224,  Precision: 0.9328185328185328, Recall: 0.9101525711056696, F1-score: 0.9213461721803794\n","Epoch 5/10, Train Loss: 0.3798, Validation Accuracy: 0.9407,  Precision: 0.9385192127460169, Recall: 0.9431154643058957, F1-score: 0.9408117249154453\n","Epoch 6/10, Train Loss: 0.3964, Validation Accuracy: 0.9251,  Precision: 0.9506690633113641, Recall: 0.8965906950461481, F1-score: 0.9228383094222566\n","Epoch 7/10, Train Loss: 0.3893, Validation Accuracy: 0.9346,  Precision: 0.9448515233320478, Recall: 0.9229610096063289, F1-score: 0.9337779895188185\n","Epoch 8/10, Train Loss: 0.3634, Validation Accuracy: 0.9751,  Precision: 0.9613977314306623, Recall: 0.9898285929553589, F1-score: 0.9754060324825986\n","Epoch 9/10, Train Loss: 0.3319, Validation Accuracy: 0.9813,  Precision: 0.9720990391722099, Recall: 0.9909587492936522, F1-score: 0.9814382986661692\n","Epoch 10/10, Train Loss: 0.3250, Validation Accuracy: 0.9794,  Precision: 0.9794649585531273, Recall: 0.9792804671312865, F1-score: 0.9793727041537157\n"]}]},{"cell_type":"code","source":["test_accuracy, precision, recall, f1_score, conf_matrix = model_trainer.test(test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdCrIraywnO3","executionInfo":{"status":"ok","timestamp":1729401501633,"user_tz":-180,"elapsed":1930,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}},"outputId":"3620656e-ffeb-4bff-ea31-384944347214"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.98%, Precision: 0.9798303487276154, Recall: 0.9770676691729323, F1-score: 0.9784470588235294\n"]}]},{"cell_type":"code","source":["print(conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IGXyu9aGcA7","executionInfo":{"status":"ok","timestamp":1729401501633,"user_tz":-180,"elapsed":11,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}},"outputId":"3050b844-ce5d-4857-c9bf-1faf9e030b44"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[[5203  107]\n"," [ 122 5198]]\n"]}]},{"cell_type":"code","source":["save_loader('/content/drive/MyDrive/Colab Notebooks/Malicious Macro Detection/LSTMClassifier.joblib', model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjf5UKDiGfKr","executionInfo":{"status":"ok","timestamp":1729401509975,"user_tz":-180,"elapsed":8349,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}},"outputId":"beea2a47-b4fc-435a-a6db-50c0daeafee1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["LSTMModel(\n","  (embedding): Embedding(304987, 128)\n","  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.5)\n","  (fc): Linear(in_features=128, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n",") saved sucessfuly\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bK8MoD87G55Z","executionInfo":{"status":"ok","timestamp":1729401509975,"user_tz":-180,"elapsed":8,"user":{"displayName":"Itamar Kraitman","userId":"10178370169469175736"}}},"execution_count":11,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOGJdtbG49CS/h1zEn+vnCW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}